// ui/viewmodel/VoiceOutputViewModel.kt
package com.example.devpath.ui.viewmodel

import android.content.Context
import android.media.AudioAttributes
import android.media.AudioFormat
import android.media.AudioTrack
import androidx.lifecycle.ViewModel
import androidx.lifecycle.viewModelScope
import com.example.devpath.api.speech.SaluteSpeechConfig
import com.example.devpath.api.speech.SaluteSpeechService
import dagger.hilt.android.lifecycle.HiltViewModel
import dagger.hilt.android.qualifiers.ApplicationContext
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.delay
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import java.io.File
import java.security.MessageDigest
import javax.inject.Inject

@HiltViewModel
class VoiceOutputViewModel @Inject constructor(
    @ApplicationContext private val context: Context,
    private val saluteSpeechService: SaluteSpeechService
) : ViewModel() {

    // –°–æ—Å—Ç–æ—è–Ω–∏—è
    private val _isSpeaking = MutableStateFlow(false)
    val isSpeaking: StateFlow<Boolean> = _isSpeaking.asStateFlow()

    private val _isVoiceEnabled = MutableStateFlow(true)
    val isVoiceEnabled: StateFlow<Boolean> = _isVoiceEnabled.asStateFlow()

    private val _selectedVoice = MutableStateFlow(SaluteSpeechConfig.DEFAULT_VOICE_FEMALE)
    val selectedVoice: StateFlow<String> = _selectedVoice.asStateFlow()

    private val _voiceSpeed = MutableStateFlow(1.0)
    val voiceSpeed: StateFlow<Double> = _voiceSpeed.asStateFlow()

    private val _selectedEmotion = MutableStateFlow<String?>(null)
    val selectedEmotion: StateFlow<String?> = _selectedEmotion.asStateFlow()

    private val _availableVoices = MutableStateFlow(SaluteSpeechConfig.AVAILABLE_VOICES)
    val availableVoices: StateFlow<List<SaluteSpeechConfig.Voice>> = _availableVoices.asStateFlow()

    private val _availableEmotions = MutableStateFlow(SaluteSpeechConfig.AVAILABLE_EMOTIONS)
    val availableEmotions: StateFlow<List<SaluteSpeechConfig.Emotion>> = _availableEmotions.asStateFlow()

    private val _error = MutableStateFlow<String?>(null)
    val error: StateFlow<String?> = _error.asStateFlow()

    private val _speakingProgress = MutableStateFlow(0f)
    val speakingProgress: StateFlow<Float> = _speakingProgress.asStateFlow()

    private val _currentSpeechText = MutableStateFlow("")
    val currentSpeechText: StateFlow<String> = _currentSpeechText.asStateFlow()

    private val _audioDuration = MutableStateFlow(0)
    val audioDuration: StateFlow<Int> = _audioDuration.asStateFlow()

    private val _currentMessageId = MutableStateFlow<Long?>(null)
    val currentMessageId: StateFlow<Long?> = _currentMessageId.asStateFlow()

    private val _cacheStats = MutableStateFlow("")
    val cacheStats: StateFlow<String> = _cacheStats.asStateFlow()

    // AudioTrack –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è PCM
    private var audioTrack: AudioTrack? = null

    // –û—á–µ—Ä–µ–¥—å —Å–æ–æ–±—â–µ–Ω–∏–π
    private val speechQueue = mutableListOf<Pair<String, Long?>>()
    private var isProcessingQueue = false

    // ‚úÖ –ö–≠–® –î–õ–Ø –ê–£–î–ò–û
    private val audioCacheDir = File(context.cacheDir, "tts_cache").apply {
        if (!exists()) mkdirs()
    }

    // –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞: 50 –ú–ë
    private val maxCacheSize = 50 * 1024 * 1024L
    private val cacheStatsMap = mutableMapOf<String, Long>()

    companion object {
        const val MAX_TEXT_LENGTH = 4000
        const val CHUNK_DELAY_MS = 500L
    }

    init {
        loadSettings()
        validateCurrentVoice()
        cleanCacheIfNeeded()
        updateCacheStats()
        println("üé§ VoiceOutput: –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω, –≥–æ–ª–æ—Å: ${_selectedVoice.value}")
        println("üìÅ TTS Cache: ${audioCacheDir.absolutePath}")
    }

    /**
     * ‚úÖ –ü–û–õ–£–ß–ò–¢–¨ –•–ï–® –¢–ï–ö–°–¢–ê –î–õ–Ø –ö–≠–®–ê
     */
    private fun getTextHash(text: String, voice: String, speed: Double): String {
        val input = "$text|$voice|$speed|${_selectedEmotion.value ?: "neutral"}"
        val bytes = MessageDigest.getInstance("MD5").digest(input.toByteArray())
        return bytes.joinToString("") { "%02x".format(it) }
    }

    /**
     * ‚úÖ –ü–û–õ–£–ß–ò–¢–¨ –ö–≠–®–ò–†–û–í–ê–ù–ù–´–ô –§–ê–ô–õ
     */
    private fun getCachedAudioFile(hash: String): File {
        return File(audioCacheDir, "$hash.pcm")
    }

    /**
     * ‚úÖ –°–û–•–†–ê–ù–ò–¢–¨ –ê–£–î–ò–û –í –ö–≠–®
     */
    private fun cacheAudioData(hash: String, audioData: ByteArray) {
        try {
            val cacheFile = getCachedAudioFile(hash)
            cacheFile.writeBytes(audioData)
            cacheStatsMap[hash] = System.currentTimeMillis()
            updateCacheStats()
            println("üíæ TTS Cache: –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ ${audioData.size} –±–∞–π—Ç, —Ö–µ—à=$hash")
        } catch (e: Exception) {
            println("‚ùå TTS Cache: –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: ${e.message}")
        }
    }

    /**
     * ‚úÖ –ó–ê–ì–†–£–ó–ò–¢–¨ –ê–£–î–ò–û –ò–ó –ö–≠–®–ê
     */
    private fun loadCachedAudio(hash: String): ByteArray? {
        return try {
            val cacheFile = getCachedAudioFile(hash)
            if (cacheFile.exists()) {
                val data = cacheFile.readBytes()
                cacheStatsMap[hash] = System.currentTimeMillis()
                println("‚úÖ TTS Cache: –ó–∞–≥—Ä—É–∂–µ–Ω–æ ${data.size} –±–∞–π—Ç, —Ö–µ—à=$hash")
                data
            } else {
                null
            }
        } catch (e: Exception) {
            println("‚ùå TTS Cache: –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: ${e.message}")
            null
        }
    }

    /**
     * ‚úÖ –û–ß–ò–°–¢–ò–¢–¨ –£–°–¢–ê–†–ï–í–®–ò–ô –ö–≠–®
     */
    private fun cleanCacheIfNeeded() {
        try {
            val files = audioCacheDir.listFiles() ?: return
            var totalSize = files.sumOf { it.length() }

            if (totalSize <= maxCacheSize) return

            // –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –¥–æ—Å—Ç—É–ø–∞
            val sortedFiles = files.sortedBy { it.lastModified() }

            for (file in sortedFiles) {
                if (totalSize <= maxCacheSize) break
                val size = file.length()
                if (file.delete()) {
                    totalSize -= size
                    println("üóëÔ∏è TTS Cache: –£–¥–∞–ª–µ–Ω ${file.name}, –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ ${size} –±–∞–π—Ç")
                }
            }

            updateCacheStats()
        } catch (e: Exception) {
            println("‚ùå TTS Cache: –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: ${e.message}")
        }
    }

    /**
     * ‚úÖ –û–ë–ù–û–í–ò–¢–¨ –°–¢–ê–¢–ò–°–¢–ò–ö–£ –ö–≠–®–ê
     */
    private fun updateCacheStats() {
        try {
            val files = audioCacheDir.listFiles() ?: return
            val count = files.size
            val size = files.sumOf { it.length() }
            val sizeMB = size / (1024.0 * 1024.0)
            val maxMB = maxCacheSize / (1024.0 * 1024.0)

            _cacheStats.value = "üì¶ –ö—ç—à TTS: $count —Ñ–∞–π–ª–æ–≤, ${"%.1f".format(sizeMB)}/${"%.1f".format(maxMB)} –ú–ë"
        } catch (e: Exception) {
            _cacheStats.value = "üì¶ –ö—ç—à TTS: –æ—à–∏–±–∫–∞"
        }
    }

    /**
     * ‚úÖ –û–ß–ò–°–¢–ò–¢–¨ –ö–≠–®
     */
    fun clearCache() {
        viewModelScope.launch {
            try {
                val files = audioCacheDir.listFiles() ?: return@launch
                var deleted = 0
                var freed = 0L

                files.forEach { file ->
                    val size = file.length()
                    if (file.delete()) {
                        deleted++
                        freed += size
                    }
                }

                cacheStatsMap.clear()
                updateCacheStats()
                println("üßπ TTS Cache: –£–¥–∞–ª–µ–Ω–æ $deleted —Ñ–∞–π–ª–æ–≤, –æ—Å–≤–æ–±–æ–∂–¥–µ–Ω–æ ${freed} –±–∞–π—Ç")

            } catch (e: Exception) {
                println("‚ùå TTS Cache: –û—à–∏–±–∫–∞ –æ—á–∏—Å—Ç–∫–∏: ${e.message}")
            }
        }
    }

    /**
     * ‚úÖ –û–ó–í–£–ß–ò–¢–¨ –î–õ–ò–ù–ù–´–ô –¢–ï–ö–°–¢ (–° –û–ë–†–ï–ó–ö–û–ô –î–û 4000)
     */
    private suspend fun speakLongText(text: String, messageId: Long? = null) {
        val chunks = text.chunked(MAX_TEXT_LENGTH)
        println("üîä VoiceOutput: –†–∞–∑–±–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ ${chunks.size} —á–∞—Å—Ç–µ–π")

        for ((index, chunk) in chunks.withIndex()) {
            if (!_isVoiceEnabled.value) break

            val isLastChunk = index == chunks.size - 1

            // ‚úÖ –û–±—Ä–µ–∑–∞–µ–º –∫–∞–∂–¥—É—é —á–∞—Å—Ç—å –¥–æ 4000 —Å–∏–º–≤–æ–ª–æ–≤
            val chunkText = if (chunk.length > MAX_TEXT_LENGTH) {
                val trimmed = chunk.take(MAX_TEXT_LENGTH - 3) + "..."
                println("   ‚ö†Ô∏è –ß–∞—Å—Ç—å ${index + 1} –æ–±—Ä–µ–∑–∞–Ω–∞ —Å ${chunk.length} –¥–æ ${trimmed.length}")
                trimmed
            } else {
                chunk
            }

            println("   –ß–∞—Å—Ç—å ${index + 1}/${chunks.size}: ${chunkText.length} —Å–∏–º–≤–æ–ª–æ–≤")

            speakTextInternal(
                text = chunkText,
                messageId = if (index == 0) messageId else null
            )

            while (_isSpeaking.value) {
                delay(100)
            }

            if (!isLastChunk) {
                delay(CHUNK_DELAY_MS)
            }
        }
    }

    /**
     * ‚úÖ –í–ù–£–¢–†–ï–ù–ù–ò–ô –ú–ï–¢–û–î –û–ó–í–£–ß–ö–ò (–° –ö–≠–®–ï–ú)
     */
    private suspend fun speakTextInternal(text: String, messageId: Long? = null) {
        try {
            stopCurrentPlayback()
            validateCurrentVoice()

            if (!isValidVoiceFormat(_selectedVoice.value)) {
                _selectedVoice.value = SaluteSpeechConfig.DEFAULT_VOICE_FEMALE
                saveSettings()
            }

            if (messageId != null) {
                _currentMessageId.value = messageId
            }

            _isSpeaking.value = true
            _currentSpeechText.value = text
            _error.value = null

            val voiceInfo = getCurrentVoiceInfo()
            println("üîä VoiceOutput: –û–∑–≤—É—á–∫–∞ (${text.length}/$MAX_TEXT_LENGTH —Å–∏–º–≤–æ–ª–æ–≤)")
            println("   –ì–æ–ª–æ—Å: ${voiceInfo?.name ?: _selectedVoice.value} (${_selectedVoice.value})")
            println("   –°–∫–æ—Ä–æ—Å—Ç—å: ${_voiceSpeed.value}x")

            // ‚úÖ –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ö–µ—à –∏ –ø—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            val hash = getTextHash(text, _selectedVoice.value, _voiceSpeed.value)
            var audioData = loadCachedAudio(hash)

            if (audioData == null) {
                println("   ‚è≥ –ö—ç—à: –ø—Ä–æ–º–∞—Ö, –∑–∞–ø—Ä–æ—Å –∫ API...")

                val result = withContext(Dispatchers.IO) {
                    saluteSpeechService.synthesizeSpeech(
                        text = text,
                        voice = _selectedVoice.value,
                        speed = _voiceSpeed.value,
                        emotion = _selectedEmotion.value,
                        format = SaluteSpeechConfig.DEFAULT_TTS_FORMAT
                    )
                }

                if (result.isSuccess) {
                    audioData = result.getOrNull()
                    if (audioData != null && audioData.isNotEmpty()) {
                        // –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à
                        cacheAudioData(hash, audioData)
                        cleanCacheIfNeeded()
                    }
                } else {
                    val error = result.exceptionOrNull()
                    _error.value = "–û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞: ${error?.message}"
                    println("‚ùå VoiceOutput: –û—à–∏–±–∫–∞ —Å–∏–Ω—Ç–µ–∑–∞: ${error?.message}")
                    _isSpeaking.value = false
                    _currentMessageId.value = null
                    return
                }
            } else {
                println("   ‚úÖ –ö—ç—à: –ø–æ–ø–∞–¥–∞–Ω–∏–µ!")
            }

            if (audioData != null && audioData.isNotEmpty()) {
                playAudioData(audioData)
            } else {
                _error.value = "–ü–æ–ª—É—á–µ–Ω—ã –ø—É—Å—Ç—ã–µ –∞—É–¥–∏–æ–¥–∞–Ω–Ω—ã–µ"
                _isSpeaking.value = false
                _currentMessageId.value = null
            }

        } catch (e: Exception) {
            _error.value = "–ò—Å–∫–ª—é—á–µ–Ω–∏–µ: ${e.message}"
            println("‚ùå VoiceOutput: –ò—Å–∫–ª—é—á–µ–Ω–∏–µ: ${e.message}")
            e.printStackTrace()
            _isSpeaking.value = false
            _currentMessageId.value = null
        }
    }

    /**
     * ‚úÖ –í–û–°–ü–†–û–ò–ó–í–ï–î–ï–ù–ò–ï –ê–£–î–ò–û
     */
    private suspend fun playAudioData(audioData: ByteArray) = withContext(Dispatchers.IO) {
        try {
            val sampleRate = if (_selectedVoice.value.contains("24000")) 24000 else 16000

            println("üîä VoiceOutput: –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∞—É–¥–∏–æ (${audioData.size} –±–∞–π—Ç, ${sampleRate}Hz)")

            val minBufferSize = AudioTrack.getMinBufferSize(
                sampleRate,
                AudioFormat.CHANNEL_OUT_MONO,
                AudioFormat.ENCODING_PCM_16BIT
            )

            val bufferSize = maxOf(minBufferSize, audioData.size)

            audioTrack = AudioTrack.Builder()
                .setAudioAttributes(
                    AudioAttributes.Builder()
                        .setUsage(AudioAttributes.USAGE_MEDIA)
                        .setContentType(AudioAttributes.CONTENT_TYPE_SPEECH)
                        .build()
                )
                .setAudioFormat(
                    AudioFormat.Builder()
                        .setEncoding(AudioFormat.ENCODING_PCM_16BIT)
                        .setSampleRate(sampleRate)
                        .setChannelMask(AudioFormat.CHANNEL_OUT_MONO)
                        .build()
                )
                .setBufferSizeInBytes(bufferSize)
                .setTransferMode(AudioTrack.MODE_STATIC)
                .build()

            audioTrack?.write(audioData, 0, audioData.size)
            audioTrack?.play()

            launchAnimation()

            while (audioTrack?.playState == AudioTrack.PLAYSTATE_PLAYING) {
                delay(10)
            }

            audioTrack?.stop()
            audioTrack?.release()
            audioTrack = null

            _isSpeaking.value = false
            _currentMessageId.value = null
            _speakingProgress.value = 0f

            println("‚úÖ VoiceOutput: –í–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")

        } catch (e: Exception) {
            println("‚ùå VoiceOutput: –û—à–∏–±–∫–∞ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è: ${e.message}")
            e.printStackTrace()
            _isSpeaking.value = false
            _currentMessageId.value = null
            audioTrack = null
        }
    }

    /**
     * ‚úÖ –ê–ù–ò–ú–ê–¶–ò–Ø –ü–†–û–ì–†–ï–°–°–ê
     */
    private suspend fun launchAnimation() {
        var progress = 0f
        while (progress < 1f && _isSpeaking.value && audioTrack?.playState == AudioTrack.PLAYSTATE_PLAYING) {
            progress += 0.01f
            _speakingProgress.value = progress.coerceIn(0f, 1f)
            delay(50)
        }
    }

    /**
     * ‚úÖ –ó–ê–ì–†–£–ó–ò–¢–¨ –ù–ê–°–¢–†–û–ô–ö–ò
     */
    private fun loadSettings() {
        try {
            val prefs = context.getSharedPreferences("voice_settings", Context.MODE_PRIVATE)
            _isVoiceEnabled.value = prefs.getBoolean("is_voice_enabled", true)
            _selectedVoice.value = prefs.getString("selected_voice", SaluteSpeechConfig.DEFAULT_VOICE_FEMALE)
                ?: SaluteSpeechConfig.DEFAULT_VOICE_FEMALE
            _voiceSpeed.value = prefs.getFloat("voice_speed", 1.0f).toDouble().coerceIn(0.5, 2.0)
            _selectedEmotion.value = prefs.getString("selected_emotion", null)
            println("üì± VoiceOutput: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
        } catch (e: Exception) {
            println("‚ùå VoiceOutput: –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞—Å—Ç—Ä–æ–µ–∫: ${e.message}")
            resetToDefaults()
        }
    }

    /**
     * ‚úÖ –°–û–•–†–ê–ù–ò–¢–¨ –ù–ê–°–¢–†–û–ô–ö–ò
     */
    private fun saveSettings() {
        try {
            val prefs = context.getSharedPreferences("voice_settings", Context.MODE_PRIVATE)
            prefs.edit().apply {
                putBoolean("is_voice_enabled", _isVoiceEnabled.value)
                putString("selected_voice", _selectedVoice.value)
                putFloat("voice_speed", _voiceSpeed.value.toFloat())
                putString("selected_emotion", _selectedEmotion.value)
                apply()
            }
            println("üíæ VoiceOutput: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã")
        } catch (e: Exception) {
            println("‚ùå VoiceOutput: –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–∫: ${e.message}")
        }
    }

    /**
     * ‚úÖ –ü–†–û–í–ï–†–ö–ê –ò –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –ì–û–õ–û–°–ê
     */
    private fun validateCurrentVoice() {
        val currentVoice = _selectedVoice.value
        if (isValidVoiceFormat(currentVoice)) return

        val correctedVoice = when {
            currentVoice.contains("16000") -> currentVoice.replace("16000", "24000")
            currentVoice == "May" -> SaluteSpeechConfig.DEFAULT_VOICE_FEMALE
            currentVoice == "Ost" -> "Ost_24000"
            currentVoice == "Bys" -> "Bys_24000"
            currentVoice == "Nez" -> "Nez_24000"
            currentVoice == "Tur" -> "Tur_24000"
            currentVoice == "Nec" -> "Nec_24000"
            currentVoice == "Pon" -> SaluteSpeechConfig.DEFAULT_VOICE_CHILD
            currentVoice == "Kin" -> "Kin_24000"
            else -> SaluteSpeechConfig.DEFAULT_VOICE_FEMALE
        }

        println("‚ö†Ô∏è VoiceOutput: –ò—Å–ø—Ä–∞–≤–ª—è–µ–º –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –≥–æ–ª–æ—Å: $currentVoice -> $correctedVoice")
        _selectedVoice.value = correctedVoice
        saveSettings()
    }

    private fun isValidVoiceFormat(voice: String): Boolean {
        return _availableVoices.value.any { it.id == voice }
    }

    /**
     * ‚úÖ –ü–û–õ–ù–û–°–¢–¨–Æ –û–°–¢–ê–ù–û–í–ò–¢–¨ –û–ó–í–£–ß–ö–£
     */
    fun stopSpeaking() {
        viewModelScope.launch {
            try {
                audioTrack?.apply {
                    if (playState == AudioTrack.PLAYSTATE_PLAYING) {
                        stop()
                    }
                    release()
                }
                audioTrack = null

                speechQueue.clear()
                isProcessingQueue = false

                _isSpeaking.value = false
                _speakingProgress.value = 0f
                _currentSpeechText.value = ""
                _currentMessageId.value = null

                println("üîá VoiceOutput: –û–∑–≤—É—á–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, –æ—á–µ—Ä–µ–¥—å –æ—á–∏—â–µ–Ω–∞")
            } catch (e: Exception) {
                println("‚ùå VoiceOutput: –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏: ${e.message}")
            }
        }
    }

    /**
     * ‚úÖ –û–°–¢–ê–ù–û–í–ò–¢–¨ –¢–ï–ö–£–©–ï–ï –í–û–°–ü–†–û–ò–ó–í–ï–î–ï–ù–ò–ï
     */
    fun stopCurrentPlayback() {
        try {
            audioTrack?.apply {
                if (playState == AudioTrack.PLAYSTATE_PLAYING) {
                    stop()
                }
                release()
            }
            audioTrack = null
            _isSpeaking.value = false
            println("üîá VoiceOutput: –¢–µ–∫—É—â–µ–µ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏–µ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ")
        } catch (e: Exception) {
            println("‚ùå VoiceOutput: –û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –≤–æ—Å–ø—Ä–æ–∏–∑–≤–µ–¥–µ–Ω–∏—è: ${e.message}")
        }
    }

    /**
     * ‚úÖ –ü–ï–†–ï–ö–õ–Æ–ß–ò–¢–¨ –û–ó–í–£–ß–ö–£
     */
    fun toggleVoiceEnabled() {
        _isVoiceEnabled.value = !_isVoiceEnabled.value
        saveSettings()

        if (!_isVoiceEnabled.value) {
            stopSpeaking()
        }

        println("üîä VoiceOutput: –û–∑–≤—É—á–∫–∞ ${if (_isVoiceEnabled.value) "–≤–∫–ª—é—á–µ–Ω–∞" else "–≤—ã–∫–ª—é—á–µ–Ω–∞"}")
    }

    /**
     * ‚úÖ –û–ó–í–£–ß–ò–¢–¨ –¢–ï–ö–°–¢
     */
    fun speakText(text: String, messageId: Long? = null) {
        if (!_isVoiceEnabled.value) {
            println("üîá VoiceOutput: –û–∑–≤—É—á–∫–∞ –æ—Ç–∫–ª—é—á–µ–Ω–∞")
            return
        }

        if (text.isBlank()) {
            println("‚ö†Ô∏è VoiceOutput: –¢–µ–∫—Å—Ç –ø—É—Å—Ç–æ–π")
            return
        }

        viewModelScope.launch {
            speechQueue.add(text to messageId)
            processQueue()
        }
    }

    /**
     * ‚úÖ –û–ë–†–ê–ë–û–¢–ö–ê –û–ß–ï–†–ï–î–ò
     */
    private suspend fun processQueue() {
        if (isProcessingQueue) return
        if (speechQueue.isEmpty()) return

        isProcessingQueue = true

        try {
            while (speechQueue.isNotEmpty()) {
                val (text, messageId) = speechQueue.removeAt(0)

                if (!_isVoiceEnabled.value) {
                    speechQueue.clear()
                    break
                }

                if (text.length > MAX_TEXT_LENGTH) {
                    println("‚ö†Ô∏è VoiceOutput: –¢–µ–∫—Å—Ç –ø—Ä–µ–≤—ã—à–∞–µ—Ç $MAX_TEXT_LENGTH —Å–∏–º–≤–æ–ª–æ–≤ (${text.length}), —Ä–∞–∑–±–∏–≤–∞–µ–º –Ω–∞ —á–∞—Å—Ç–∏")
                    speakLongText(text, messageId)
                } else {
                    speakTextInternal(text, messageId)
                }

                while (_isSpeaking.value) {
                    delay(100)
                }

                delay(200)
            }
        } finally {
            isProcessingQueue = false
        }
    }

    /**
     * ‚úÖ –£–°–¢–ê–ù–û–í–ò–¢–¨ –ì–û–õ–û–°
     */
    fun setVoice(voiceId: String) {
        if (isValidVoiceFormat(voiceId)) {
            _selectedVoice.value = voiceId
            saveSettings()
            val voiceInfo = getCurrentVoiceInfo()
            println("üé§ VoiceOutput: –í—ã–±—Ä–∞–Ω –≥–æ–ª–æ—Å: ${voiceInfo?.name ?: voiceId} ($voiceId)")
        } else {
            println("‚ùå VoiceOutput: –ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –≥–æ–ª–æ—Å–∞: $voiceId")
        }
    }

    /**
     * ‚úÖ –£–°–¢–ê–ù–û–í–ò–¢–¨ –°–ö–û–†–û–°–¢–¨
     */
    fun setVoiceSpeed(speed: Double) {
        _voiceSpeed.value = speed.coerceIn(0.5, 2.0)
        saveSettings()
        println("‚ö° VoiceOutput: –°–∫–æ—Ä–æ—Å—Ç—å —Ä–µ—á–∏: ${_voiceSpeed.value}x")
    }

    /**
     * ‚úÖ –£–°–¢–ê–ù–û–í–ò–¢–¨ –≠–ú–û–¶–ò–Æ
     */
    fun setEmotion(emotion: String?) {
        _selectedEmotion.value = emotion
        saveSettings()
        println("üòä VoiceOutput: –≠–º–æ—Ü–∏—è: ${emotion ?: "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è"}")
    }

    fun getCurrentVoiceInfo(): SaluteSpeechConfig.Voice? {
        return _availableVoices.value.find { it.id == _selectedVoice.value }
    }

    fun clearError() {
        _error.value = null
    }

    fun resetToDefaults() {
        _isVoiceEnabled.value = true
        _selectedVoice.value = SaluteSpeechConfig.DEFAULT_VOICE_FEMALE
        _voiceSpeed.value = 1.0
        _selectedEmotion.value = null
        saveSettings()
        println("üîÑ VoiceOutput: –°–±—Ä–æ—Å –Ω–∞—Å—Ç—Ä–æ–µ–∫")
    }

    fun forceClearSettings() {
        val prefs = context.getSharedPreferences("voice_settings", Context.MODE_PRIVATE)
        prefs.edit().clear().apply()
        resetToDefaults()
        println("üßπ VoiceOutput: –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –æ—á–∏—â–µ–Ω—ã")
    }

    fun testVoice() {
        val voiceInfo = getCurrentVoiceInfo()
        val testText = when {
            voiceInfo?.gender == "–ú—É–∂—Å–∫–æ–π" -> "–ü—Ä–∏–≤–µ—Ç! –Ø ${voiceInfo.name}. –ú–æ–π –≥–æ–ª–æ—Å –∑–≤—É—á–∏—Ç —Ç–∞–∫."
            voiceInfo?.gender == "–ñ–µ–Ω—Å–∫–∏–π" -> "–ü—Ä–∏–≤–µ—Ç! –Ø ${voiceInfo.name}. –ú–æ–π –≥–æ–ª–æ—Å –∑–≤—É—á–∏—Ç —Ç–∞–∫."
            else -> "–ü—Ä–∏–≤–µ—Ç! –Ø –≥–æ–ª–æ—Å–æ–≤–æ–π –ø–æ–º–æ—â–Ω–∏–∫. –≠—Ç–æ—Ç –≥–æ–ª–æ—Å –∑–≤—É—á–∏—Ç —Ç–∞–∫."
        }
        speakText(testText)
    }

    fun getVoiceStats(): String {
        val voiceInfo = getCurrentVoiceInfo()
        return """
            Voice Settings:
            ‚îú‚îÄ –ì–æ–ª–æ—Å: ${voiceInfo?.name ?: _selectedVoice.value}
            ‚îú‚îÄ ID: ${_selectedVoice.value}
            ‚îú‚îÄ –ü–æ–ª: ${voiceInfo?.gender ?: "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–æ"}
            ‚îú‚îÄ –ö–∞—á–µ—Å—Ç–≤–æ: 24kHz
            ‚îú‚îÄ –°–∫–æ—Ä–æ—Å—Ç—å: ${_voiceSpeed.value}x
            ‚îú‚îÄ –≠–º–æ—Ü–∏—è: ${_selectedEmotion.value ?: "–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–∞—è"}
            ‚îú‚îÄ –û–∑–≤—É—á–∫–∞: ${if (_isVoiceEnabled.value) "–≤–∫–ª—é—á–µ–Ω–∞" else "–≤—ã–∫–ª—é—á–µ–Ω–∞"}
            ‚îî‚îÄ ${_cacheStats.value}
        """.trimIndent()
    }

    override fun onCleared() {
        super.onCleared()
        stopSpeaking()
        println("üîÑ VoiceOutputViewModel –æ—á–∏—â–µ–Ω")
    }
}