// ui/viewmodel/VoiceInputViewModel.kt
package com.example.devpath.ui.viewmodel

import android.Manifest
import android.content.Context
import android.content.pm.PackageManager
import android.media.MediaRecorder
import android.os.Build
import androidx.core.content.ContextCompat
import androidx.lifecycle.ViewModel
import androidx.lifecycle.viewModelScope
import com.example.devpath.api.speech.SaluteSpeechService
import dagger.hilt.android.lifecycle.HiltViewModel
import dagger.hilt.android.qualifiers.ApplicationContext
import kotlinx.coroutines.delay
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.StateFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.flow.update
import kotlinx.coroutines.launch
import kotlinx.coroutines.Job
import java.io.File
import java.text.SimpleDateFormat
import java.util.*
import javax.inject.Inject

@HiltViewModel
class VoiceInputViewModel @Inject constructor(
    @ApplicationContext private val context: Context,
    private val saluteSpeechService: SaluteSpeechService
) : ViewModel() {

    // –°–æ—Å—Ç–æ—è–Ω–∏—è
    private val _isRecording = MutableStateFlow(false)
    val isRecording: StateFlow<Boolean> = _isRecording.asStateFlow()

    private val _isProcessing = MutableStateFlow(false)
    val isProcessing: StateFlow<Boolean> = _isProcessing.asStateFlow()

    private val _recognizedText = MutableStateFlow("")
    val recognizedText: StateFlow<String> = _recognizedText.asStateFlow()

    private val _error = MutableStateFlow<String?>(null)
    val error: StateFlow<String?> = _error.asStateFlow()

    private val _audioLevel = MutableStateFlow(0f)
    val audioLevel: StateFlow<Float> = _audioLevel.asStateFlow()

    private val _recordingDuration = MutableStateFlow(0)
    val recordingDuration: StateFlow<Int> = _recordingDuration.asStateFlow()

    private var mediaRecorder: MediaRecorder? = null
    private var audioFile: File? = null
    private var startTime: Long = 0

    // Jobs –¥–ª—è –∫–æ—Ä—É—Ç–∏–Ω –≤–º–µ—Å—Ç–æ Timer
    private var durationJob: Job? = null
    private var audioLevelJob: Job? = null

    // –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ
    fun hasRecordAudioPermission(): Boolean {
        return ContextCompat.checkSelfPermission(
            context,
            Manifest.permission.RECORD_AUDIO
        ) == PackageManager.PERMISSION_GRANTED
    }

    // –ù–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å –≥–æ–ª–æ—Å–∞
    fun startRecording() {
        if (!hasRecordAudioPermission()) {
            _error.value = "–ù–µ—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –∑–∞–ø–∏—Å—å –∞—É–¥–∏–æ"
            return
        }

        viewModelScope.launch {
            try {
                // –°–æ–∑–¥–∞–µ–º —Ñ–∞–π–ª –¥–ª—è –∑–∞–ø–∏—Å–∏
                audioFile = createAudioFile()

                // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MediaRecorder —Å —Å–æ–≤–º–µ—Å—Ç–∏–º—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
                mediaRecorder = if (Build.VERSION.SDK_INT >= Build.VERSION_CODES.S) {
                    MediaRecorder(context)
                } else {
                    MediaRecorder()
                }.apply {
                    setAudioSource(MediaRecorder.AudioSource.MIC)

                    // –ò—Å–ø–æ–ª—å–∑—É–µ–º 3GP —Ñ–æ—Ä–º–∞—Ç (–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç—Å—è –Ω–∞ –≤—Å–µ—Ö API —É—Ä–æ–≤–Ω—è—Ö)
                    setOutputFormat(MediaRecorder.OutputFormat.THREE_GPP)
                    setAudioEncoder(MediaRecorder.AudioEncoder.AMR_NB)
                    setAudioSamplingRate(8000)
                    setOutputFile(audioFile?.absolutePath)

                    prepare()
                    start()
                }

                _isRecording.value = true
                _error.value = null
                startTime = System.currentTimeMillis()

                // –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–∞–π–º–µ—Ä –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∑–∞–ø–∏—Å–∏ —Å –ø–æ–º–æ—â—å—é –∫–æ—Ä—É—Ç–∏–Ω
                startDurationTimer()

                // –ó–∞–ø—É—Å–∫–∞–µ–º –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞ —Å –ø–æ–º–æ—â—å—é –∫–æ—Ä—É—Ç–∏–Ω
                startAudioLevelMonitor()

                println("üé§ VoiceInput: –ù–∞—á–∞–ª–æ –∑–∞–ø–∏—Å–∏, —Ñ–∞–π–ª: ${audioFile?.absolutePath}")

            } catch (e: Exception) {
                _error.value = "–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏: ${e.message}"
                e.printStackTrace()
                cleanup()
            }
        }
    }

    // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å
    fun stopRecording() {
        try {
            mediaRecorder?.apply {
                try {
                    stop()
                } catch (e: Exception) {
                    // –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏
                }
                release()
            }
            mediaRecorder = null

            // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∫–æ—Ä—É—Ç–∏–Ω—ã
            stopTimers()

            _isRecording.value = false
            _audioLevel.value = 0f

            val duration = if (startTime > 0) (System.currentTimeMillis() - startTime) / 1000 else 0
            println("üé§ VoiceInput: –ó–∞–ø–∏—Å—å –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞, –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: ${duration}—Å")

        } catch (e: Exception) {
            _error.value = "–û—à–∏–±–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏: ${e.message}"
            e.printStackTrace()
        }
    }

    // –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∑–∞–ø–∏—Å—å –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç
    fun stopRecordingAndRecognize(onResult: ((String) -> Unit)? = null) {
        stopRecording()

        audioFile?.let { file ->
            if (file.exists() && file.length() > 0) {
                recognizeAudio(file, onResult)
            } else {
                _error.value = "–§–∞–π–ª –∑–∞–ø–∏—Å–∏ –ø—É—Å—Ç –∏–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç"
                onResult?.invoke("")
            }
        }
    }

    // –†–∞—Å–ø–æ–∑–Ω–∞—Ç—å –∞—É–¥–∏–æ—Ñ–∞–π–ª
    private fun recognizeAudio(file: File, onResult: ((String) -> Unit)? = null) {
        viewModelScope.launch {
            _isProcessing.value = true

            try {
                println("üé§ VoiceInput: –û—Ç–ø—Ä–∞–≤–∫–∞ –Ω–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ, —Ä–∞–∑–º–µ—Ä: ${file.length()} –±–∞–π—Ç")

                // –ò—Å–ø–æ–ª—å–∑—É–µ–º AMR –∫–æ–¥–µ–∫ –¥–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
                val result = saluteSpeechService.recognizeSpeech(
                    audioFile = file,
                    mimeType = "audio/amr"
                )

                if (result.isSuccess) {
                    val text = result.getOrNull() ?: ""
                    _recognizedText.value = text
                    println("‚úÖ VoiceInput: –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: \"$text\"")

                    // –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
                    try {
                        file.delete()
                    } catch (e: Exception) {
                        println("‚ö†Ô∏è VoiceInput: –ù–µ —É–¥–∞–ª–æ—Å—å —É–¥–∞–ª–∏—Ç—å —Ñ–∞–π–ª: ${e.message}")
                    }

                    onResult?.invoke(text)
                } else {
                    val error = result.exceptionOrNull()
                    _error.value = "–û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: ${error?.message}"
                    println("‚ùå VoiceInput: –û—à–∏–±–∫–∞ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è: ${error?.message}")
                    onResult?.invoke("")
                }

            } catch (e: Exception) {
                _error.value = "–ò—Å–∫–ª—é—á–µ–Ω–∏–µ –ø—Ä–∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–∏: ${e.message}"
                e.printStackTrace()
                onResult?.invoke("")
            } finally {
                _isProcessing.value = false
            }
        }
    }

    // ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ó–∞–ø—É—Å–∫ —Ç–∞–π–º–µ—Ä–∞ –¥–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å –ø–æ–º–æ—â—å—é –∫–æ—Ä—É—Ç–∏–Ω (–≤–º–µ—Å—Ç–æ Timer)
    private fun startDurationTimer() {
        durationJob = viewModelScope.launch {
            while (_isRecording.value) {
                val duration = (System.currentTimeMillis() - startTime) / 1000
                _recordingDuration.value = duration.toInt()
                delay(1000) // –ó–∞–¥–µ—Ä–∂–∫–∞ 1 —Å–µ–∫—É–Ω–¥–∞
            }
        }
    }

    // ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —É—Ä–æ–≤–Ω—è –∑–≤—É–∫–∞ —Å –ø–æ–º–æ—â—å—é –∫–æ—Ä—É—Ç–∏–Ω (–≤–º–µ—Å—Ç–æ Timer)
    private fun startAudioLevelMonitor() {
        audioLevelJob = viewModelScope.launch {
            while (_isRecording.value && mediaRecorder != null) {
                try {
                    val maxAmplitude = mediaRecorder!!.maxAmplitude
                    val level = if (maxAmplitude > 0) {
                        (Math.log10(maxAmplitude.toDouble()) * 20).toFloat()
                    } else {
                        0f
                    }
                    _audioLevel.value = level.coerceIn(0f, 100f) / 100f
                } catch (e: Exception) {
                    // –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –∞–º–ø–ª–∏—Ç—É–¥—ã
                }
                delay(100) // –ó–∞–¥–µ—Ä–∂–∫–∞ 100 –º—Å
            }
        }
    }

    // ‚úÖ –ò–°–ü–†–ê–í–õ–ï–ù–û: –û—Å—Ç–∞–Ω–æ–≤–∫–∞ —Ç–∞–π–º–µ—Ä–æ–≤
    private fun stopTimers() {
        durationJob?.cancel()
        durationJob = null
        audioLevelJob?.cancel()
        audioLevelJob = null
    }

    // –°–æ–∑–¥–∞—Ç—å —Ñ–∞–π–ª –¥–ª—è –∞—É–¥–∏–æ–∑–∞–ø–∏—Å–∏
    private fun createAudioFile(): File {
        val timeStamp = SimpleDateFormat("yyyyMMdd_HHmmss", Locale.getDefault()).format(Date())
        val audioFileName = "VOICE_INPUT_${timeStamp}.amr"

        val storageDir = File(context.cacheDir, "voice_recording")
        if (!storageDir.exists()) {
            storageDir.mkdirs()
        }

        return File(storageDir, audioFileName).apply {
            createNewFile()
        }
    }

    // –û—á–∏—Å—Ç–∫–∞
    private fun cleanup() {
        stopTimers()

        try {
            mediaRecorder?.release()
            mediaRecorder = null
        } catch (e: Exception) {
            e.printStackTrace()
        }

        try {
            audioFile?.delete()
        } catch (e: Exception) {
            e.printStackTrace()
        }
        audioFile = null

        _isRecording.value = false
        _isProcessing.value = false
        _audioLevel.value = 0f
        _recordingDuration.value = 0
    }

    // –û—á–∏—Å—Ç–∏—Ç—å —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
    fun clearRecognizedText() {
        _recognizedText.value = ""
    }

    // –û—á–∏—Å—Ç–∏—Ç—å –æ—à–∏–±–∫—É
    fun clearError() {
        _error.value = null
    }

    // –°–±—Ä–æ—Å–∏—Ç—å —Å–æ—Å—Ç–æ—è–Ω–∏–µ
    fun reset() {
        cleanup()
        _recognizedText.value = ""
        _error.value = null
    }

    override fun onCleared() {
        super.onCleared()
        cleanup()
    }
}